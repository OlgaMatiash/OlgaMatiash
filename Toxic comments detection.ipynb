{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1b9d01",
   "metadata": {},
   "source": [
    "# Toxic comments detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0410fa",
   "metadata": {},
   "source": [
    "\n",
    "The online store 'Vikishop' is launching a new service. Now users can edit and enhance product descriptions, similar to wiki communities. In other words, customers can suggest edits and comment on other people's changes. The store needs a tool that can detect toxic comments and send them for moderation.\n",
    "\n",
    "Train a model to classify comments as positive or negative. You have a dataset with annotations indicating the toxicity of edits.\n",
    "\n",
    "Build a model with an F1 quality metric of at least 0.75\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54feca43",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8904287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc31881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = '/datasets/toxic_comments.csv'\n",
    "pth2 = 'C:/Users/n.kirpichnikov/Desktop/Оля Учеба/Проекты/comments review/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    data = pd.read_csv(pth1)\n",
    "elif os.path.exists(pth2):\n",
    "    data = pd.read_csv(pth2)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf41d999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)\n",
    "display(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007b4f9",
   "metadata": {},
   "source": [
    "We have 159291 comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7350140e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5e3f5",
   "metadata": {},
   "source": [
    "The number of toxic comments is 16,186, and the number of regular comments is 143,106."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc82c06",
   "metadata": {},
   "source": [
    "Let's write a function called \"clear_text(text)\" that will keep only Latin characters and spaces in the text. It takes the text as input and returns the cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe2ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    clean_text = re.sub(r\"[^a-zA-Z']\", ' ', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ec154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f51e25b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww  He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man  I'm really not trying to edit war  It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>More I can't make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You  sir  are my hero  Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>And for the second time of asking  when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself   That is a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer   Umm  theres no actual article for pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>And     I really don't think you understand ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation Why the edits made under my userna...      0\n",
       "1                1  D'aww  He matches this background colour I'm s...      0\n",
       "2                2  Hey man  I'm really not trying to edit war  It...      0\n",
       "3                3    More I can't make any real suggestions on im...      0\n",
       "4                4  You  sir  are my hero  Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446        And for the second time of asking  when ...      0\n",
       "159288      159447  You should be ashamed of yourself   That is a ...      0\n",
       "159289      159448  Spitzer   Umm  theres no actual article for pr...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450    And     I really don't think you understand ...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8186782",
   "metadata": {},
   "source": [
    " Lemmatize the text using nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2101966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\n.kirpichnikov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "wnl = WordNetLemmatizer()\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "def lemmatize(text, m=wnl):\n",
    "    word_list = tknzr.tokenize(text)\n",
    "    tagged_words = pos_tag(word_list)\n",
    "    lemmatized_words = []\n",
    "    for word, tag in tagged_words:\n",
    "        if tag.startswith('N'):  # Nouns\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('V'):  # Verbs\n",
    "            pos = 'v'\n",
    "        elif tag.startswith('R'):  # Adverbs\n",
    "            pos = 'r'\n",
    "        else:  # Adjectives and others\n",
    "            pos = 'a'\n",
    "        lemmatized_words.append(m.lemmatize(word, pos=pos))\n",
    "    return ' '.join(lemmatized_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a084b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53714aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww He match this background colour I'm seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man I'm really not try to edit war It's ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>More I can't make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You sir be my hero Any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>And for the second time of ask when your view ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself That be a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it look like it be actually you who put on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>And I really don't think you understand I come...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation Why the edits make under my userna...      0\n",
       "1                1  D'aww He match this background colour I'm seem...      0\n",
       "2                2  Hey man I'm really not try to edit war It's ju...      0\n",
       "3                3  More I can't make any real suggestion on impro...      0\n",
       "4                4  You sir be my hero Any chance you remember wha...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  And for the second time of ask when your view ...      0\n",
       "159288      159447  You should be ashamed of yourself That be a ho...      0\n",
       "159289      159448  Spitzer Umm theres no actual article for prost...      0\n",
       "159290      159449  And it look like it be actually you who put on...      0\n",
       "159291      159450  And I really don't think you understand I come...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd9d05",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9f6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['toxic']\n",
    "features = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df86aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7e23ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, fit_time, score_time, f1-score]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = pd.DataFrame(columns=('model','fit_time','score_time','f1-score'))\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d8e18",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de3195",
   "metadata": {},
   "source": [
    "Download stopwords base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "089a379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\n.kirpichnikov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d48c6",
   "metadata": {},
   "source": [
    "To count the TF-IDF for a text corpus, we can use the \"fit\" function for the training set and the \"transform\" function for both the test and training sets.\n",
    "\n",
    "The counter will identify the unique words in the corpus and count their occurrences in each text. The method will return a matrix where each row represents a text and each column represents a unique word from the entire corpus. The number at their intersection indicates how many times the specific word appeared in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70185ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(\n",
    "    [\n",
    "        (\"tf_idf\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"model_lr\", LogisticRegression(random_state=12345, solver = 'liblinear', class_weight='balanced')),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985eb25",
   "metadata": {},
   "source": [
    " Initiate the GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585bdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr = {\n",
    "          'model_lr__class_weight':['balanced'],\n",
    "          'model_lr__C':[8,10,12],\n",
    "          'model_lr__max_iter':[500]}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98fd6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr=GridSearchCV(estimator=pipeline_lr, cv=5, param_grid = params_lr, scoring='f1', n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34648fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tf_idf',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('model_lr',\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           random_state=12345,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model_lr__C': [8, 10, 12],\n",
       "                         'model_lr__class_weight': ['balanced'],\n",
       "                         'model_lr__max_iter': [500]},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b502fcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_lr__C': 10, 'model_lr__class_weight': 'balanced', 'model_lr__max_iter': 500} 0.7631816162431637\n"
     ]
    }
   ],
   "source": [
    "print(grid_lr.best_params_, grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc3ba6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_lr.cv_results_\n",
    "\n",
    "best_index = grid_lr.best_index_\n",
    "\n",
    "\n",
    "fit_time = results['mean_fit_time'][best_index]\n",
    "score_time = results['mean_score_time'][best_index]\n",
    "F1 = (grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0921aecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>16.809028</td>\n",
       "      <td>2.35814</td>\n",
       "      <td>0.763182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model   fit_time  score_time  f1-score\n",
       "0  logistic_regression  16.809028     2.35814  0.763182"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_data = ['logistic_regression', fit_time, score_time, F1]\n",
    "\n",
    "model_data.loc[len(model_data)] = lr_data \n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddb20d",
   "metadata": {},
   "source": [
    "### Random Forest Classifyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ff0ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline(\n",
    "    [\n",
    "        (\"tf_idf\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"model_rf\", RandomForestClassifier(random_state=12345)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b2e1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "          'model_rf__class_weight':['balanced'],\n",
    "           'model_rf__max_depth':[10,20,30],\n",
    "        'model_rf__n_estimators':[100,200,300]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72c27874",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf=GridSearchCV(estimator=pipeline_rf, cv=5, param_grid = params_rf, scoring='f1', n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0c7f7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tf_idf',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('model_rf',\n",
       "                                        RandomForestClassifier(random_state=12345))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model_rf__class_weight': ['balanced'],\n",
       "                         'model_rf__max_depth': [10, 20, 30],\n",
       "                         'model_rf__n_estimators': [100, 200, 300]},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "261f085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_rf__class_weight': 'balanced', 'model_rf__max_depth': 30, 'model_rf__n_estimators': 300} 0.43154895295118034\n"
     ]
    }
   ],
   "source": [
    "print(grid_rf.best_params_, grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7660ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_rf.cv_results_\n",
    "\n",
    "best_index = grid_rf.best_index_\n",
    "\n",
    "\n",
    "fit_time = results['mean_fit_time'][best_index]\n",
    "score_time = results['mean_score_time'][best_index]\n",
    "F1 = (grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99cb471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>16.809028</td>\n",
       "      <td>2.358140</td>\n",
       "      <td>0.763182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf_classifyer</td>\n",
       "      <td>112.200676</td>\n",
       "      <td>3.672404</td>\n",
       "      <td>0.431549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model    fit_time  score_time  f1-score\n",
       "0  logistic_regression   16.809028    2.358140  0.763182\n",
       "1        rf_classifyer  112.200676    3.672404  0.431549"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data = ['rf_classifyer', fit_time, score_time, F1]\n",
    "\n",
    "model_data.loc[len(model_data)] = rf_data \n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf76c29",
   "metadata": {},
   "source": [
    "## Testing the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff873f2",
   "metadata": {},
   "source": [
    "We can observe that logistic_regression shows the best performance. Let's proceed with testing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a4758e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = grid_lr.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2014de79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7718197375926982"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(target_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7395d3",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57be27",
   "metadata": {},
   "source": [
    "We were selecting the optimal model for the online store \"WikiShop\" that would detect toxic comments and send them for moderation.\n",
    "\n",
    "To achieve this, we loaded a database of comments labeled with their toxicity status. The database contained over 159,000 comments, with more than 16,000 being toxic and over 143,000 being normal comments. The target variable was imbalanced, which was taken into account during model training.\n",
    "\n",
    "Next, we performed tokenization (splitting the text into a list of words) and lemmatization (converting words to their base form) while excluding unnecessary symbols, retaining only Latin alphabet letters, apostrophes, and spaces.\n",
    "\n",
    "We then loaded a stop words database and transformed the text strings into vectors using TfidfVectorizer(stop_words=stopwords), incorporating the stop words. This resulted in a TF-IDF matrix, which we used as features.\n",
    "\n",
    "In other words, we tackled a classification problem where the target variable was \"1\" for positive text and \"0\" for negative text. The features consisted of words and their respective TF-IDF values for each text.\n",
    "\n",
    "After text preprocessing, we trained two classifiers and evaluated their performance using cross-validation. To avoid data leakage during cross-validation, we placed the model and vectorizer in a pipeline.\n",
    "\n",
    "As a result, the logistic regression model outperformed the random forest model. Therefore, we conducted the testing phase on the logistic regression model. The testing demonstrated an F1 score higher than the required threshold of 0.75 according to the task conditions. Thus, this model is suitable for our purposes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df662ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
